<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 10]
- [cs.CL](#cs.CL) [Total: 4]
- [cs.AI](#cs.AI) [Total: 4]
- [cs.IT](#cs.IT) [Total: 5]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [BiRQA: Bidirectional Robust Quality Assessment for Images](https://arxiv.org/abs/2602.20351)
*Aleksandr Gushchin,Dmitriy S. Vatolin,Anastasia Antsiferova*

Main category: cs.CV

TL;DR: BiRQA是一个紧凑的全参考图像质量评估模型，采用双向多尺度金字塔处理四个快速互补特征，通过锚定对抗训练提升鲁棒性，在保持高精度的同时实现实时处理速度。


<details>
  <summary>Details</summary>
Motivation: 当前神经图像质量评估指标存在速度慢且容易受到对抗性扰动攻击的问题，需要开发既准确又鲁棒且高效的评估模型。

Method: 1. 双向多尺度金字塔架构：处理四个快速互补特征；2. 自底向上注意力模块：通过不确定性感知门将细粒度线索注入粗粒度层级；3. 自顶向下交叉门控块：将语义上下文路由回高分辨率；4. 锚定对抗训练：使用干净"锚点"样本和排序损失来限制攻击下的逐点预测误差。

Result: 1. 在五个公共FR IQA基准测试中优于或匹配先前SOTA；2. 运行速度比先前SOTA模型快约3倍；3. 在未见过的白盒攻击下，KADID-10k上的SROCC从0.30-0.57提升到0.60-0.84；4. 结合了竞争性精度、实时吞吐量和强对抗鲁棒性。

Conclusion: BiRQA是首个同时具备竞争性精度、实时处理能力和强对抗鲁棒性的全参考图像质量评估模型，为图像压缩、修复和生成建模提供了高效可靠的评估工具。

Abstract: Full-Reference image quality assessment (FR IQA) is important for image compression, restoration and generative modeling, yet current neural metrics remain slow and vulnerable to adversarial perturbations. We present BiRQA, a compact FR IQA metric model that processes four fast complementary features within a bidirectional multiscale pyramid. A bottom-up attention module injects fine-scale cues into coarse levels through an uncertainty-aware gate, while a top-down cross-gating block routes semantic context back to high resolution. To enhance robustness, we introduce Anchored Adversarial Training, a theoretically grounded strategy that uses clean "anchor" samples and a ranking loss to bound pointwise prediction error under attacks. On five public FR IQA benchmarks BiRQA outperforms or matches the previous state of the art (SOTA) while running ~3x faster than previous SOTA models. Under unseen white-box attacks it lifts SROCC from 0.30-0.57 to 0.60-0.84 on KADID-10k, demonstrating substantial robustness gains. To our knowledge, BiRQA is the only FR IQA model combining competitive accuracy with real-time throughput and strong adversarial resilience.

</details>


### [2] [3DSPA: A 3D Semantic Point Autoencoder for Evaluating Video Realism](https://arxiv.org/abs/2602.20354)
*Bhavik Chandna,Kelsey R. Allen*

Main category: cs.CV

TL;DR: 3DSPA是一个自动评估视频真实性的框架，通过3D时空点自编码器整合3D点轨迹、深度线索和语义特征，无需参考视频即可评估视频的真实性、时间一致性和物理合理性。


<details>
  <summary>Details</summary>
Motivation: 当前AI视频生成发展迅速，但评估生成视频的真实性仍主要依赖人工标注或有限范围的评估数据集，缺乏自动化、全面的评估方法。

Method: 提出3DSPA方法，这是一个3D时空点自编码器，将3D点轨迹、深度线索和DINO语义特征整合到统一的视频表示中，建模物体运动和场景内容。

Result: 实验表明3DSPA能可靠识别违反物理规律的视频，对运动伪影更敏感，在多个数据集上与人类对视频质量和真实性的判断更一致。

Conclusion: 将3D语义信息融入基于轨迹的表示，为生成视频模型的基准测试提供了更强的基础，并能隐式捕捉物理规则违反。

Abstract: AI video generation is evolving rapidly. For video generators to be useful for applications ranging from robotics to film-making, they must consistently produce realistic videos. However, evaluating the realism of generated videos remains a largely manual process -- requiring human annotation or bespoke evaluation datasets which have restricted scope. Here we develop an automated evaluation framework for video realism which captures both semantics and coherent 3D structure and which does not require access to a reference video. Our method, 3DSPA, is a 3D spatiotemporal point autoencoder which integrates 3D point trajectories, depth cues, and DINO semantic features into a unified representation for video evaluation. 3DSPA models how objects move and what is happening in the scene, enabling robust assessments of realism, temporal consistency, and physical plausibility. Experiments show that 3DSPA reliably identifies videos which violate physical laws, is more sensitive to motion artifacts, and aligns more closely with human judgments of video quality and realism across multiple datasets. Our results demonstrate that enriching trajectory-based representations with 3D semantics offers a stronger foundation for benchmarking generative video models, and implicitly captures physical rule violations. The code and pretrained model weights will be available at https://github.com/TheProParadox/3dspa_code.

</details>


### [3] [CLIPoint3D: Language-Grounded Few-Shot Unsupervised 3D Point Cloud Domain Adaptation](https://arxiv.org/abs/2602.20409)
*Mainak Singha,Sarthak Mehrotra,Paolo Casari,Subhasis Chaudhuri,Elisa Ricci,Biplab Banerjee*

Main category: cs.CV

TL;DR: CLIPoint3D：首个基于CLIP的少样本无监督3D点云域适应框架，通过多深度图投影、知识驱动提示调优和参数高效微调，在合成到真实点云域适应中实现显著性能提升


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型（如CLIP）在跨模态推理方面表现出色，但在域适应方面脆弱，特别是在从合成点云到真实点云的适应中。传统3D域适应方法依赖重型可训练编码器，虽然准确率高但效率低下。

Method: 1) 将3D样本投影到多个深度图；2) 利用冻结的CLIP主干，通过知识驱动提示调优方案进行精炼，整合高级语言先验和轻量级3D编码器的几何线索；3) 对CLIP编码器应用参数高效微调；4) 设计熵引导视图采样策略选择置信投影；5) 使用基于最优传输的对齐损失和不确定性感知原型对齐损失协同桥接源-目标分布差距并保持类别可分性。

Result: 在PointDA-10和GraspNetPC-10基准测试中，CLIPoint3D相比基于CLIP和传统编码器的基线方法，实现了3-16%的准确率提升。

Conclusion: CLIPoint3D是首个基于CLIP的少样本无监督3D点云域适应框架，通过有效整合语言先验和几何线索，在保持效率的同时显著提升了域适应性能。

Abstract: Recent vision-language models (VLMs) such as CLIP demonstrate impressive cross-modal reasoning, extending beyond images to 3D perception. Yet, these models remain fragile under domain shifts, especially when adapting from synthetic to real-world point clouds. Conventional 3D domain adaptation approaches rely on heavy trainable encoders, yielding strong accuracy but at the cost of efficiency. We introduce CLIPoint3D, the first framework for few-shot unsupervised 3D point cloud domain adaptation built upon CLIP. Our approach projects 3D samples into multiple depth maps and exploits the frozen CLIP backbone, refined through a knowledge-driven prompt tuning scheme that integrates high-level language priors with geometric cues from a lightweight 3D encoder. To adapt task-specific features effectively, we apply parameter-efficient fine-tuning to CLIP's encoders and design an entropy-guided view sampling strategy for selecting confident projections. Furthermore, an optimal transport-based alignment loss and an uncertainty-aware prototype alignment loss collaboratively bridge source-target distribution gaps while maintaining class separability. Extensive experiments on PointDA-10 and GraspNetPC-10 benchmarks show that CLIPoint3D achieves consistent 3-16% accuracy gains over both CLIP-based and conventional encoder-based baselines. Codes are available at https://github.com/SarthakM320/CLIPoint3D.

</details>


### [4] [SimLBR: Learning to Detect Fake Images by Learning to Detect Real Images](https://arxiv.org/abs/2602.20412)
*Aayush Dhakal,Subash Khanal,Srikumar Sastry,Jacob Arndt,Philipe Ambrozio Dias,Dalton Lunga,Nathan Jacobs*

Main category: cs.CV

TL;DR: SimLBR提出了一种基于潜在混合正则化的AI生成图像检测框架，通过围绕真实图像分布学习紧密决策边界，将虚假类别视为汇类，显著提升跨生成器泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的虚假图像检测方法容易过拟合训练数据，在具有强分布偏移的硬测试集上表现灾难性失败，需要更可靠的检测方法。

Method: 提出SimLBR框架，采用潜在混合正则化(LBR)技术，学习围绕真实图像分布的紧密决策边界，将虚假类别视为汇类而非独立类别。

Result: 在Chameleon基准测试中，SimLBR实现了高达+24.85%的准确率和+69.62%的召回率提升，训练速度比现有方法快几个数量级。

Conclusion: SimLBR为AI生成图像检测提供了简单高效的解决方案，显著提升了跨生成器泛化能力，同时强调了可靠性导向评估的重要性。

Abstract: The rapid advancement of generative models has made the detection of AI-generated images a critical challenge for both research and society. Recent works have shown that most state-of-the-art fake image detection methods overfit to their training data and catastrophically fail when evaluated on curated hard test sets with strong distribution shifts. In this work, we argue that it is more principled to learn a tight decision boundary around the real image distribution and treat the fake category as a sink class. To this end, we propose SimLBR, a simple and efficient framework for fake image detection using Latent Blending Regularization (LBR). Our method significantly improves cross-generator generalization, achieving up to +24.85\% accuracy and +69.62\% recall on the challenging Chameleon benchmark. SimLBR is also highly efficient, training orders of magnitude faster than existing approaches. Furthermore, we emphasize the need for reliability-oriented evaluation in fake image detection, introducing risk-adjusted metrics and worst-case estimates to better assess model robustness. All code and models will be released on HuggingFace and GitHub.

</details>


### [5] [MedCLIPSeg: Probabilistic Vision-Language Adaptation for Data-Efficient and Generalizable Medical Image Segmentation](https://arxiv.org/abs/2602.20423)
*Taha Koleilat,Hojat Asgariandehkordi,Omid Nejati Manzari,Berardino Barile,Yiming Xiao,Hassan Rivaz*

Main category: cs.CV

TL;DR: MedCLIPSeg：基于CLIP的医学图像分割框架，通过概率跨模态注意力实现文本引导的医学图像分割，提高数据效率和领域泛化能力


<details>
  <summary>Details</summary>
Motivation: 医学图像分割面临标注数据有限、解剖特征模糊和领域偏移等挑战。虽然CLIP等视觉语言模型提供强大的跨模态表示能力，但其在密集、文本引导的医学图像分割中的应用潜力尚未充分探索

Method: 提出MedCLIPSeg框架，通过概率跨模态注意力利用patch级CLIP嵌入，实现图像和文本token的双向交互，并显式建模预测不确定性。结合软patch级对比损失，促进不同文本提示间的语义学习

Result: 在涵盖5种成像模态和6个器官的16个数据集上的实验表明，MedCLIPSeg在准确性、效率和鲁棒性方面优于现有方法，同时提供可解释的不确定性图来突出分割结果的局部可靠性

Conclusion: 这项工作展示了概率视觉语言建模在文本驱动医学图像分割中的潜力，为数据高效、领域泛化的医学图像分割提供了新思路

Abstract: Medical image segmentation remains challenging due to limited annotations for training, ambiguous anatomical features, and domain shifts. While vision-language models such as CLIP offer strong cross-modal representations, their potential for dense, text-guided medical image segmentation remains underexplored. We present MedCLIPSeg, a novel framework that adapts CLIP for robust, data-efficient, and uncertainty-aware medical image segmentation. Our approach leverages patch-level CLIP embeddings through probabilistic cross-modal attention, enabling bidirectional interaction between image and text tokens and explicit modeling of predictive uncertainty. Together with a soft patch-level contrastive loss that encourages more nuanced semantic learning across diverse textual prompts, MedCLIPSeg effectively improves data efficiency and domain generalizability. Extensive experiments across 16 datasets spanning five imaging modalities and six organs demonstrate that MedCLIPSeg outperforms prior methods in accuracy, efficiency, and robustness, while providing interpretable uncertainty maps that highlight local reliability of segmentation results. This work demonstrates the potential of probabilistic vision-language modeling for text-driven medical image segmentation.

</details>


### [6] [SceMoS: Scene-Aware 3D Human Motion Synthesis by Planning with Geometry-Grounded Tokens](https://arxiv.org/abs/2602.20476)
*Anindita Ghosh,Vladislav Golyanik,Taku Komura,Philipp Slusallek,Christian Theobalt,Rishabh Dabral*

Main category: cs.CV

TL;DR: SceMoS：基于2D场景表示的3D人体运动合成框架，通过分离全局规划和局部执行，使用BEV图像和局部高度图替代昂贵的3D监督，在保持物理真实性的同时显著减少参数和计算成本。


<details>
  <summary>Details</summary>
Motivation: 当前基于3D场景数据（点云、体素网格）的运动合成方法计算成本高，同时学习高层规划和低层接触推理。需要一种更高效的方法来合成语义意图明确且物理可行的场景感知运动。

Method: 1. 文本条件自回归全局运动规划器：使用DINOv2特征编码的鸟瞰图作为场景表示；2. 几何基础运动分词器：通过条件VQ-VAE训练，使用2D局部场景高度图，将表面物理直接嵌入离散词汇表。

Result: 在TRUMANS基准测试中达到最先进的运动真实性和接触精度，场景编码可训练参数减少超过50%，证明2D场景线索能有效支撑3D人-场景交互。

Conclusion: 结构化2D场景表示可以作为完整3D监督的强大替代方案，实现效率与保真度的平衡：BEV语义捕获空间布局和可供性用于全局推理，局部高度图确保细粒度物理遵循而无需完整3D体积推理。

Abstract: Synthesizing text-driven 3D human motion within realistic scenes requires learning both semantic intent ("walk to the couch") and physical feasibility (e.g., avoiding collisions). Current methods use generative frameworks that simultaneously learn high-level planning and low-level contact reasoning, and rely on computationally expensive 3D scene data such as point clouds or voxel occupancy grids. We propose SceMoS, a scene-aware motion synthesis framework that shows that structured 2D scene representations can serve as a powerful alternative to full 3D supervision in physically grounded motion synthesis. SceMoS disentangles global planning from local execution using lightweight 2D cues and relying on (1) a text-conditioned autoregressive global motion planner that operates on a bird's-eye-view (BEV) image rendered from an elevated corner of the scene, encoded with DINOv2 features, as the scene representation, and (2) a geometry-grounded motion tokenizer trained via a conditional VQ-VAE, that uses 2D local scene heightmap, thus embedding surface physics directly into a discrete vocabulary. This 2D factorization reaches an efficiency-fidelity trade-off: BEV semantics capture spatial layout and affordance for global reasoning, while local heightmaps enforce fine-grained physical adherence without full 3D volumetric reasoning. SceMoS achieves state-of-the-art motion realism and contact accuracy on the TRUMANS benchmark, reducing the number of trainable parameters for scene encoding by over 50%, showing that 2D scene cues can effectively ground 3D human-scene interaction.

</details>


### [7] [The Finite Primitive Basis Theorem for Computational Imaging: Formal Foundations of the OperatorGraph Representation](https://arxiv.org/abs/2602.20550)
*Chengshuai Yang*

Main category: cs.CV

TL;DR: 论文证明所有成像前向模型都可用11个基本原语构建的有向无环图近似表示，建立了物理世界模型的数学基础。


<details>
  <summary>Details</summary>
Motivation: 传统计算成像前向模型通常作为特定模态的单一代码实现，缺乏统一的数学框架。本文旨在为广泛的成像模态建立统一的表示理论。

Method: 定义了成像操作符类Cimg，证明其中所有前向模型都可用11个基本原语构建的有向无环图ε近似表示。提供了构造算法，并证明原语库是最小的。

Result: 在31个线性模态上验证了ε<0.01，最多5个节点和深度5。为9个非线性模态提供了构造性DAG分解。非线性被分为点式标量函数和自洽迭代两类。

Conclusion: 建立了有限原语基定理，为物理世界模型框架提供了数学基础，实现了成像前向模型的统一表示。

Abstract: Computational imaging forward models, from coded aperture spectral cameras to MRI scanners, are traditionally implemented as monolithic, modality-specific codes. We prove that every forward model in a broad, precisely defined operator class Cimg (encompassing clinical, scientific, and industrial imaging modalities, both linear and nonlinear) admits an epsilon-approximate representation as a typed directed acyclic graph (DAG) whose nodes are drawn from a library of exactly 11 canonical primitives: Propagate, Modulate, Project, Encode, Convolve, Accumulate, Detect, Sample, Disperse, Scatter, and Transform. We call this the Finite Primitive Basis Theorem. The proof is constructive: we provide an algorithm that, given any H in Cimg, produces a DAG G with relative operator error at most epsilon and graph complexity within prescribed bounds. We further prove that the library is minimal: removing any single primitive causes at least one modality to lose its epsilon-approximate representation. A systematic analysis of nonlinearities in imaging physics shows they fall into two structural categories: pointwise scalar functions (handled by Transform) and self-consistent iterations (unrolled into existing linear primitives). Empirical validation on 31 linear modalities confirms eimg below 0.01 with at most 5 nodes and depth 5, and we provide constructive DAG decompositions for 9 additional nonlinear modalities. These results establish mathematical foundations for the Physics World Model (PWM) framework.

</details>


### [8] [LUMEN: Longitudinal Multi-Modal Radiology Model for Prognosis and Diagnosis](https://arxiv.org/abs/2602.21142)
*Zhifan Jiang,Dong Yang,Vishwesh Nath,Abhijeet Parida,Nishad P. Kulkarni,Ziyue Xu,Daguang Xu,Syed Muhammad Anwar,Holger R. Roth,Marius George Linguraru*

Main category: cs.CV

TL;DR: 本文提出LUMEN训练框架，通过多图像多任务指令微调优化纵向胸部X光片解读，提升预后和诊断性能


<details>
  <summary>Details</summary>
Motivation: 放射科医生分析纵向影像变化对准确诊断和预后至关重要，但手动纵向分析耗时，需要开发具有预后能力的训练框架

Method: 提出LUMEN训练框架，采用多图像和多任务指令微调优化纵向CXR解读；构建包含纵向研究的指令跟随数据集，支持预后VQA任务开发

Result: 在MIMIC-CXR和Medical-Diff-VQA数据集上实验显示，相比基线模型在诊断VQA任务上有显著改进，并在预后能力方面展现出有前景的潜力

Conclusion: 精心设计的指令微调视觉语言模型能够实现更准确、更具临床意义的纵向放射影像解读，为临床决策支持提供价值

Abstract: Large vision-language models (VLMs) have evolved from general-purpose applications to specialized use cases such as in the clinical domain, demonstrating potential for decision support in radiology. One promising application is assisting radiologists in decision-making by the analysis of radiology imaging data such as chest X-rays (CXR) via a visual and natural language question-answering (VQA) interface. When longitudinal imaging is available, radiologists analyze temporal changes, which are essential for accurate diagnosis and prognosis. The manual longitudinal analysis is a time-consuming process, motivating the development of a training framework that can provide prognostic capabilities. We introduce a novel training framework LUMEN, that is optimized for longitudinal CXR interpretation, leveraging multi-image and multi-task instruction fine-tuning to enhance prognostic and diagnostic performance. We conduct experiments on the publicly available MIMIC-CXR and its associated Medical-Diff-VQA datasets. We further formulate and construct a novel instruction-following dataset incorporating longitudinal studies, enabling the development of a prognostic VQA task. Our method demonstrates significant improvements over baseline models in diagnostic VQA tasks, and more importantly, shows promising potential for prognostic capabilities. These results underscore the value of well-designed, instruction-tuned VLMs in enabling more accurate and clinically meaningful radiological interpretation of longitudinal radiological imaging data.

</details>


### [9] [Seeing Through Words: Controlling Visual Retrieval Quality with Language Models](https://arxiv.org/abs/2602.21175)
*Jianglin Lu,Simon Jenni,Kushal Kafle,Jing Shi,Handong Zhao,Yun Fu*

Main category: cs.CV

TL;DR: 本文提出了一种质量可控的文本到图像检索新范式，通过生成语言模型将简短查询扩展为包含细粒度视觉属性和质量控制的描述性查询，无需修改现有视觉语言模型即可显著提升检索效果。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的文本到图像检索面临简短用户查询的挑战：这些查询通常只有一两个词，语义模糊，容易产生多种视觉解释冲突，且缺乏对检索图像质量的显式控制。

Method: 提出质量可控检索框架，利用生成语言模型作为查询补全函数，将简短查询扩展为包含姿态、场景、美学等细粒度视觉属性的描述性查询。通过基于相关性和美学评分模型的离散化质量级别来条件化查询补全，实现语义丰富且质量感知的查询扩展。

Result: 实验表明，该方法显著改善了检索结果并提供了有效的质量控制，弥合了现代视觉语言模型表达能力与简短用户查询不明确性之间的差距。系统具有灵活性（兼容任何预训练VLM）、透明性（扩展查询可解释）和可控性（可引导至用户偏好质量级别）三大优势。

Conclusion: 提出的质量可控检索新范式成功解决了简短查询在文本到图像检索中的局限性，通过查询扩展和质量控制相结合，为实际应用提供了更有效的检索解决方案。

Abstract: Text-to-image retrieval is a fundamental task in vision-language learning, yet in real-world scenarios it is often challenged by short and underspecified user queries. Such queries are typically only one or two words long, rendering them semantically ambiguous, prone to collisions across diverse visual interpretations, and lacking explicit control over the quality of retrieved images. To address these issues, we propose a new paradigm of quality-controllable retrieval, which enriches short queries with contextual details while incorporating explicit notions of image quality. Our key idea is to leverage a generative language model as a query completion function, extending underspecified queries into descriptive forms that capture fine-grained visual attributes such as pose, scene, and aesthetics. We introduce a general framework that conditions query completion on discretized quality levels, derived from relevance and aesthetic scoring models, so that query enrichment is not only semantically meaningful but also quality-aware. The resulting system provides three key advantages: 1) flexibility, it is compatible with any pretrained vision-language model (VLMs) without modification; 2) transparency, enriched queries are explicitly interpretable by users; and 3) controllability, enabling retrieval results to be steered toward user-preferred quality levels. Extensive experiments demonstrate that our proposed approach significantly improves retrieval results and provides effective quality control, bridging the gap between the expressive capacity of modern VLMs and the underspecified nature of short user queries. Our code is available at https://github.com/Jianglin954/QCQC.

</details>


### [10] [Spa3R: Predictive Spatial Field Modeling for 3D Visual Reasoning](https://arxiv.org/abs/2602.21186)
*Haoyi Jiang,Liu Liu,Xinjie Wang,Yonghao He,Wei Sui,Zhizhong Su,Wenyu Liu,Xinggang Wang*

Main category: cs.CV

TL;DR: Spa3R框架通过自监督学习从无姿态多视角图像中学习统一、视角不变的空间表示，无需显式3D模态或空间指令微调，实现了从2D视觉中涌现空间智能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型(VLMs)在3D空间理解方面表现肤浅，现有方法要么依赖显式3D模态，要么通过部分视角条件几何先验增强VLMs，这些方法限制了可扩展性，并让语言模型承担了从稀疏线索隐式重建整体3D几何的不适定任务。

Method: 提出Spa3R自监督框架，基于预测性空间场建模(PSFM)范式，从无姿态多视角图像学习统一、视角不变的空间表示。Spa3R学习为任意未见视角合成特征场，条件于紧凑潜在表示，从而内化对底层3D场景的整体连贯理解。通过轻量适配器将预训练的Spa3R编码器集成到现有VLMs中，形成Spa3-VLM。

Result: 在具有挑战性的VSI-Bench上，Spa3-VLM在3D视觉问答任务中达到58.6%的最先进准确率，显著优于先前方法。

Conclusion: PSFM为推进空间智能提供了一条可扩展的路径，证明空间智能可以从2D视觉中自然涌现，而无需通过显式空间指令微调强加。

Abstract: While Vision-Language Models (VLMs) exhibit exceptional 2D visual understanding, their ability to comprehend and reason about 3D space--a cornerstone of spatial intelligence--remains superficial. Current methodologies attempt to bridge this domain gap either by relying on explicit 3D modalities or by augmenting VLMs with partial, view-conditioned geometric priors. However, such approaches hinder scalability and ultimately burden the language model with the ill-posed task of implicitly reconstructing holistic 3D geometry from sparse cues. In this paper, we argue that spatial intelligence can emerge inherently from 2D vision alone, rather than being imposed via explicit spatial instruction tuning. To this end, we introduce Spa3R, a self-supervised framework that learns a unified, view-invariant spatial representation directly from unposed multi-view images. Spa3R is built upon the proposed Predictive Spatial Field Modeling (PSFM) paradigm, where Spa3R learns to synthesize feature fields for arbitrary unseen views conditioned on a compact latent representation, thereby internalizing a holistic and coherent understanding of the underlying 3D scene. We further integrate the pre-trained Spa3R Encoder into existing VLMs via a lightweight adapter to form Spa3-VLM, effectively grounding language reasoning in a global spatial context. Experiments on the challenging VSI-Bench demonstrate that Spa3-VLM achieves state-of-the-art accuracy of 58.6% on 3D VQA, significantly outperforming prior methods. These results highlight PSFM as a scalable path toward advancing spatial intelligence. Code is available at https://github.com/hustvl/Spa3R.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [11] [What Makes a Good Query? Measuring the Impact of Human-Confusing Linguistic Features on LLM Performance](https://arxiv.org/abs/2602.20300)
*William Watson,Nicole Cho,Sumitra Ganesh,Manuela Veloso*

Main category: cs.CL

TL;DR: 研究发现查询语句的特定结构特征（如从句嵌套深度、指代不明确等）与LLM幻觉风险相关，为查询重写和干预研究提供了实证基础。


<details>
  <summary>Details</summary>
Motivation: 传统上LLM幻觉被视为模型或解码策略的缺陷，但本文从语言学角度出发，认为查询语句的形式也会影响模型响应。研究旨在探索特定类型的查询是否更容易引发幻觉。

Method: 构建22维查询特征向量，涵盖从句复杂度、词汇稀有度、指代、否定、可回答性和意图明确性等语言学特征。使用369,837个真实世界查询进行大规模分析，识别与幻觉风险相关的查询特征模式。

Result: 分析揭示了稳定的"风险图谱"：深度从句嵌套和指代不明确等特征与更高的幻觉倾向相关；而意图明确和可回答性则与较低的幻觉率相关。其他特征如领域特异性则呈现混合、依赖数据集和模型的效果。

Conclusion: 研究建立了与幻觉风险相关的可观测查询特征表示，为引导性查询重写和未来干预研究铺平了道路，表明通过优化查询结构可以降低LLM幻觉风险。

Abstract: Large Language Model (LLM) hallucinations are usually treated as defects of the model or its decoding strategy. Drawing on classical linguistics, we argue that a query's form can also shape a listener's (and model's) response. We operationalize this insight by constructing a 22-dimension query feature vector covering clause complexity, lexical rarity, and anaphora, negation, answerability, and intention grounding, all known to affect human comprehension. Using 369,837 real-world queries, we ask: Are there certain types of queries that make hallucination more likely? A large-scale analysis reveals a consistent "risk landscape": certain features such as deep clause nesting and underspecification align with higher hallucination propensity. In contrast, clear intention grounding and answerability align with lower hallucination rates. Others, including domain specificity, show mixed, dataset- and model-dependent effects. Thus, these findings establish an empirically observable query-feature representation correlated with hallucination risk, paving the way for guided query rewriting and future intervention studies.

</details>


### [12] [No One Size Fits All: QueryBandits for Hallucination Mitigation](https://arxiv.org/abs/2602.20332)
*Nicole Cho,William Watson,Alec Koppel,Sumitra Ganesh,Manuela Veloso*

Main category: cs.CL

TL;DR: QueryBandits框架通过上下文多臂老虎机在线学习选择最优查询重写策略，减少闭源大语言模型的幻觉问题，无需重新训练或梯度调整。


<details>
  <summary>Details</summary>
Motivation: 闭源大语言模型在机构部署中占主导地位，但现有缓解幻觉的研究主要针对开源模型进行事后检测和参数编辑，缺乏对闭源模型的专门研究。

Method: 提出QueryBandits框架，这是一个模型无关的上下文多臂老虎机系统，通过经验验证和校准的奖励函数在线学习选择最优查询重写策略（如改写、扩展等）。

Result: 在16个QA场景中，最佳QueryBandits（Thompson Sampling）相比无重写基线获得87.5%的胜率，分别比零样本静态策略（改写和扩展）高出42.6%和60.3%。上下文老虎机在所有数据集上都优于普通老虎机。

Conclusion: 没有单一的重写策略适用于所有查询，僵化的重写策略可能加剧幻觉。QueryBandits通过前向传递机制在线学习语义特征策略，可用于闭源模型而无需重新训练或梯度调整。

Abstract: Advanced reasoning capabilities in Large Language Models (LLMs) have led to more frequent hallucinations; yet most mitigation work focuses on open-source models for post-hoc detection and parameter editing. The dearth of studies focusing on hallucinations in closed-source models is especially concerning, as they constitute the vast majority of models in institutional deployments. We introduce QueryBandits, a model-agnostic contextual bandit framework that adaptively learns online to select the optimal query-rewrite strategy by leveraging an empirically validated and calibrated reward function. Across 16 QA scenarios, our top QueryBandit (Thompson Sampling) achieves an 87.5% win rate over a No-Rewrite baseline and outperforms zero-shot static policies (e.g., Paraphrase or Expand) by 42.6% and 60.3%, respectively. Moreover, all contextual bandits outperform vanilla bandits across all datasets, with higher feature variance coinciding with greater variance in arm selection. This substantiates our finding that there is no single rewrite policy optimal for all queries. We also discover that certain static policies incur higher cumulative regret than No-Rewrite, indicating that an inflexible query-rewriting policy can worsen hallucinations. Thus, learning an online policy over semantic features with QueryBandits can shift model behavior purely through forward-pass mechanisms, enabling its use with closed-source models and bypassing the need for retraining or gradient-based adaptation.

</details>


### [13] [How communicatively optimal are exact numeral systems? Once more on lexicon size and morphosyntactic complexity](https://arxiv.org/abs/2602.20372)
*Chundra Cathcart,Arne Rubehn,Katja Bocklage,Luca Ciucci,Kellen Parker van Dam,Alžběta Kučerová,Jekaterina Mažara,Carlo Y. Meloni,David Snee,Johann-Mattis List*

Main category: cs.CL

TL;DR: 研究发现许多语言的数字系统在沟通效率上不如预期，挑战了精确递归数字系统能优化效率的观点


<details>
  <summary>Details</summary>
Motivation: 先前研究认为精确递归数字系统通过平衡数字词汇库大小和数字术语的平均形态句法复杂性来优化沟通效率，但作者认为这些研究未能充分解释语言所表现出的复杂性程度

Method: 使用来自52种遗传多样语言的数据，采用区分可预测和不可预测异形（形式变异）的注释方案进行分析

Result: 研究表明世界上许多语言的数字系统在沟通效率上明显低于预期水平

Conclusion: 研究结果对数字系统研究和更广泛的语言演化研究具有重要意义，挑战了现有关于数字系统效率优化的理论

Abstract: Recent research argues that exact recursive numeral systems optimize communicative efficiency by balancing a tradeoff between the size of the numeral lexicon and the average morphosyntactic complexity (roughly length in morphemes) of numeral terms. We argue that previous studies have not characterized the data in a fashion that accounts for the degree of complexity languages display. Using data from 52 genetically diverse languages and an annotation scheme distinguishing between predictable and unpredictable allomorphy (formal variation), we show that many of the world's languages are decisively less efficient than one would expect. We discuss the implications of our findings for the study of numeral systems and linguistic evolution more generally.

</details>


### [14] [Stop-Think-AutoRegress: Language Modeling with Latent Diffusion Planning](https://arxiv.org/abs/2602.20528)
*Justin Lovelace,Christian Belardi,Sofian Zalouk,Adhitya Polavaram,Srivatsa Kundurthy,Kilian Q. Weinberger*

Main category: cs.CL

TL;DR: STAR-LDM是一种结合潜在扩散规划和自回归生成的语言模型，通过"思考"阶段在连续空间进行全局规划，再生成离散标记，在语言理解和推理任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统自回归语言模型受限于逐标记决策，缺乏全局规划能力。STAR-LDM旨在通过引入扩散规划机制，让模型在生成前进行"思考"，在连续语义空间进行全局规划，从而提升语言理解和生成质量。

Method: STAR-LDM整合了潜在扩散规划和自回归生成。模型包含一个"思考"阶段，在生成过程中暂停，通过扩散过程在连续空间精炼语义计划，然后再继续自回归生成离散标记。架构还支持通过轻量级分类器进行直接控制。

Result: STAR-LDM在语言理解基准测试上显著优于相似规模的模型，在LLM作为评判者的比较中，在叙事连贯性和常识推理方面获得超过70%的胜率。架构允许通过轻量级分类器进行细粒度控制，无需重新训练模型，在流畅性和控制之间取得更好平衡。

Conclusion: STAR-LDM通过整合扩散规划和自回归生成，为语言模型提供了全局规划能力，显著提升了语言理解和生成质量，同时支持有效的控制机制，为语言模型架构提供了新的方向。

Abstract: The Stop-Think-AutoRegress Language Diffusion Model (STAR-LDM) integrates latent diffusion planning with autoregressive generation. Unlike conventional autoregressive language models limited to token-by-token decisions, STAR-LDM incorporates a "thinking" phase that pauses generation to refine a semantic plan through diffusion before continuing. This enables global planning in continuous space prior to committing to discrete tokens. Evaluations show STAR-LDM significantly outperforms similar-sized models on language understanding benchmarks and achieves $>70\%$ win rates in LLM-as-judge comparisons for narrative coherence and commonsense reasoning. The architecture also allows straightforward control through lightweight classifiers, enabling fine-grained steering of attributes without model retraining while maintaining better fluency-control trade-offs than specialized approaches.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [15] [Diffusion Modulation via Environment Mechanism Modeling for Planning](https://arxiv.org/abs/2602.20422)
*Hanping Zhang,Yuhong Guo*

Main category: cs.AI

TL;DR: 提出DMEMM方法，通过建模环境机制来调制扩散模型，解决传统扩散规划方法在离线强化学习中轨迹一致性问题


<details>
  <summary>Details</summary>
Motivation: 传统基于扩散的规划方法在离线强化学习中生成轨迹时，未能充分考虑环境机制的一致性要求，导致生成的轨迹与真实环境机制存在显著差异

Method: 提出DMEMM方法，通过建模环境机制（特别是转移动态和奖励函数）来调制扩散模型的训练过程

Result: 实验结果表明DMEMM在离线强化学习的规划任务中达到了最先进的性能

Conclusion: 通过将环境机制建模融入扩散模型训练，DMEMM能够生成更符合真实环境一致性的轨迹，显著提升离线强化学习规划效果

Abstract: Diffusion models have shown promising capabilities in trajectory generation for planning in offline reinforcement learning (RL). However, conventional diffusion-based planning methods often fail to account for the fact that generating trajectories in RL requires unique consistency between transitions to ensure coherence in real environments. This oversight can result in considerable discrepancies between the generated trajectories and the underlying mechanisms of a real environment. To address this problem, we propose a novel diffusion-based planning method, termed as Diffusion Modulation via Environment Mechanism Modeling (DMEMM). DMEMM modulates diffusion model training by incorporating key RL environment mechanisms, particularly transition dynamics and reward functions. Experimental results demonstrate that DMEMM achieves state-of-the-art performance for planning with offline reinforcement learning.

</details>


### [16] [PreScience: A Benchmark for Forecasting Scientific Contributions](https://arxiv.org/abs/2602.20459)
*Anirudh Ajith,Amanpreet Singh,Jay DeYoung,Nadav Kunievsky,Austin C. Kozlowski,Oyvind Tafjord,James Evans,Daniel S. Weld,Tom Hope,Doug Downey*

Main category: cs.AI

TL;DR: 论文提出了PreScience基准测试，用于评估AI系统能否基于历史科学记录预测未来的科学发展，包含合作者预测、参考文献选择、贡献生成和影响力预测四个任务，发现当前AI模型在这些任务上仍有很大提升空间。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索AI系统能否基于截止某个时间点的科学记录来预测后续的科学发展。这种能力可以帮助研究人员识别合作者、发现有影响力的研究方向，并预测哪些问题和方法将成为未来的研究重点。

Method: 提出了PreScience基准测试，包含四个相互依赖的生成任务：合作者预测、参考文献选择、贡献生成和影响力预测。构建了包含98K篇AI相关论文的数据集，包含消歧的作者身份、时间对齐的学术元数据，以及包含502K篇论文的作者发表历史和引用关系的结构化图。开发了LACERScore这一新的LLM-based贡献相似度度量方法。

Result: 研究发现每个任务仍有很大提升空间：在贡献生成任务中，前沿LLM与真实贡献的相似度仅为中等水平（GPT-5平均得分5.6/10）。当将四个任务组合成12个月的端到端科学生产模拟时，生成的合成语料库在多样性和新颖性方面都系统性地低于同期人类撰写的研究。

Conclusion: AI系统基于历史科学记录预测未来科学发展的能力仍然有限，特别是在生成多样化和新颖的研究方面。PreScience基准为评估和改进科学预测能力提供了系统框架，LACERScore作为新的评估指标优于先前方法。

Abstract: Can AI systems trained on the scientific record up to a fixed point in time forecast the scientific advances that follow? Such a capability could help researchers identify collaborators and impactful research directions, and anticipate which problems and methods will become central next. We introduce PreScience -- a scientific forecasting benchmark that decomposes the research process into four interdependent generative tasks: collaborator prediction, prior work selection, contribution generation, and impact prediction. PreScience is a carefully curated dataset of 98K recent AI-related research papers, featuring disambiguated author identities, temporally aligned scholarly metadata, and a structured graph of companion author publication histories and citations spanning 502K total papers. We develop baselines and evaluations for each task, including LACERScore, a novel LLM-based measure of contribution similarity that outperforms previous metrics and approximates inter-annotator agreement. We find substantial headroom remains in each task -- e.g. in contribution generation, frontier LLMs achieve only moderate similarity to the ground-truth (GPT-5, averages 5.6 on a 1-10 scale). When composed into a 12-month end-to-end simulation of scientific production, the resulting synthetic corpus is systematically less diverse and less novel than human-authored research from the same period.

</details>


### [17] [KairosVL: Orchestrating Time Series and Semantics for Unified Reasoning](https://arxiv.org/abs/2602.20494)
*Haotian Si,Changhua Pei,Xiao He,Zeyan Li,Zhe Xie,Zexin Wang,Jiyao Hu,Zhaoyang Yu,Tieying Zhang,Dan Pei,Jianhui Li,Gaogang Xie*

Main category: cs.AI

TL;DR: 提出语义条件时间序列推理任务，通过两轮强化学习框架增强模型对时间序列的语义理解和推理能力，开发出KairosVL模型，在合成和真实任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 针对时间序列分析日益复杂和决策导向的需求，传统数值建模方法已不足以满足需要，需要结合上下文和语义理解，扩展时间序列分析的能力边界。

Method: 提出两轮强化学习框架：第一轮强化模型对基本时间原语的感知能力，第二轮专注于语义条件推理。开发出KairosVL模型实现这一框架。

Result: KairosVL在合成和真实世界任务中取得竞争性表现，实验和消融研究表明该框架不仅提升性能，还保持内在推理能力，显著提高对未见场景的泛化能力。

Conclusion: 该工作展示了语义推理与时间建模结合的潜力，为现实世界时间序列智能提供了实用框架，满足了当前对复杂时间序列分析的迫切需求。

Abstract: Driven by the increasingly complex and decision-oriented demands of time series analysis, we introduce the Semantic-Conditional Time Series Reasoning task, which extends conventional time series analysis beyond purely numerical modeling to incorporate contextual and semantic understanding. To further enhance the mode's reasoning capabilities on complex time series problems, we propose a two-round reinforcement learning framework: the first round strengthens the mode's perception of fundamental temporal primitives, while the second focuses on semantic-conditioned reasoning. The resulting model, KairosVL, achieves competitive performance across both synthetic and real-world tasks. Extensive experiments and ablation studies demonstrate that our framework not only boosts performance but also preserves intrinsic reasoning ability and significantly improves generalization to unseen scenarios. To summarize, our work highlights the potential of combining semantic reasoning with temporal modeling and provides a practical framework for real-world time series intelligence, which is in urgent demand.

</details>


### [18] [Inner Speech as Behavior Guides: Steerable Imitation of Diverse Behaviors for Human-AI coordination](https://arxiv.org/abs/2602.20517)
*Rakshit Trivedi,Kartik Sharma,David C Parkes*

Main category: cs.AI

TL;DR: MIMIC框架使用语言作为行为意图的内部表示，通过视觉语言模型训练条件变分自编码器生成内部语音，再基于扩散的行为克隆策略选择动作，实现了在推理时对行为的细粒度控制。


<details>
  <summary>Details</summary>
Motivation: 当前模仿学习方法难以捕捉人类行为的多样性和非马尔可夫特性，且缺乏在推理时引导行为的能力。受人类认知过程中内部语音指导动作选择的启发，需要一种能够使用语言作为行为意图内部表示的方法。

Method: 提出MIMIC框架：1) 使用视觉语言模型作为语言支架训练条件变分自编码器，从观察中生成内部语音；2) 基于扩散的行为克隆策略，根据当前观察和生成的内部语音选择动作；3) 在推理时通过特定行为语音条件化智能体实现行为引导。

Result: 在机器人操作任务和人机协作游戏中，MIMIC显著提高了行为多样性和对人类演示的保真度，同时实现了无需额外演示训练的细粒度行为引导。

Conclusion: MIMIC通过将语言作为行为意图的内部表示，成功解决了当前模仿学习方法在捕捉行为多样性和推理时行为引导方面的局限性，为人机协调提供了更有效的解决方案。

Abstract: Effective human-AI coordination requires artificial agents capable of exhibiting and responding to human-like behaviors while adapting to changing contexts. Imitation learning has emerged as one of the prominent approaches to build such agents by training them to mimic human-demonstrated behaviors. However, current methods struggle to capture the inherent diversity and non-Markovian nature of human behavior and lack the ability to steer behavior at inference time. Drawing inspiration from the theory of human cognitive processes, where inner speech guides action selection before execution, we propose MIMIC (Modeling Inner Motivations for Imitation and Control), a framework that uses language as an internal representation of behavioral intent. MIMIC employs the novel use of vision-language models as linguistic scaffolding to train a conditional variational autoencoder capable of generating inner speech from observations. A diffusion-based behavior cloning policy then selects actions conditioned on current observations and the generated inner speech. MIMIC enables fine-grained steering of behavior at inference time by conditioning the agent on behavior-specific speech. Experiments across robotic manipulation tasks and human-AI collaboration games demonstrate that MIMIC significantly enhances both behavior diversity and fidelity to human demonstrations while enabling nuanced behavioral steering without training on additional demonstrations. We open source our code and provide pre-trained MIMIC agents and qualitative demos at: https://mimic-research.github.io.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [19] [Insertion Correcting Capability for Quantum Deletion-Correcting Codes](https://arxiv.org/abs/2602.20635)
*Ken Nakamura,Takayuki Nozaki*

Main category: cs.IT

TL;DR: 该论文证明量子t删除纠错码在一定条件下也能纠正总共t个插入和删除错误，并提出了量子插入删除距离的概念来描述量子码的插入删除纠错能力。


<details>
  <summary>Details</summary>
Motivation: 研究量子码在插入和删除错误下的纠错能力，将经典编码理论中的概念扩展到量子领域，为量子通信和存储中的实际错误类型提供理论支持。

Method: 1. 证明量子t删除纠错码在一定条件下也能纠正总共t个插入和删除错误；2. 定义量子插入删除距离；3. 使用类似经典编码理论中的错误球不相交条件来定义量子纠错码。

Result: 建立了量子码在插入和删除错误下的纠错理论框架，证明了删除纠错码与插入删除纠错码之间的等价关系，并提出了量化纠错能力的度量标准。

Conclusion: 量子插入删除纠错码理论为量子信息处理提供了新的理论工具，将经典编码理论中的插入删除纠错概念成功扩展到量子领域，具有重要的理论意义和应用价值。

Abstract: This paper proves that any quantum t-deletion-correcting codes also correct a total of t insertion and deletion errors under a certain condition. Here, this condition is that a set of quantum states is defined as a quantum error-correcting code if the error spheres of its states are disjoint, as classical coding theory. In addition, this paper proposes the quantum indel distance and describes insertion and deletion errors correcting capability of quantum codes by this distance.

</details>


### [20] [Delay Alignment Modulation for Secure ISAC Systems](https://arxiv.org/abs/2602.21114)
*Tianyu Lu,Jiajun He,Mohammadali Mohammadi,Michail Matthaiou*

Main category: cs.IT

TL;DR: DAM技术通过控制多径延迟对齐增强合法用户信号，同时使窃听者信号失配，提升ISAC系统的安全性和感知性能。


<details>
  <summary>Details</summary>
Motivation: 多用户下行链路的广播特性使通信易受窃听，同时多径传播会降低感知性能，需要一种能同时增强通信安全和感知准确性的技术。

Method: 提出延迟对齐调制(DAM)，在发射端控制每径符号延迟，使多径分量在合法用户处相干对齐；采用两阶段协议先估计角度再估计LoS路径延迟；开发基于路径的ZF预编码框架，在CRB和功率约束下最大化最小SSE。

Result: 仿真结果显示DAM在SSE方面显著优于最强径基准方案，同时满足感知要求，因为故意延迟对齐在合法用户处增强信号而在窃听者处降低接收质量。

Conclusion: DAM为安全ISAC提供了一种有效解决方案，通过延迟对齐增强合法用户信号同时使窃听者信号失配，实现了通信安全和感知性能的平衡。

Abstract: This paper introduces delay-alignment modulation (DAM) for secure integrated sensing and communication (ISAC). Due to the broadcast nature of multi-user downlinks, communications are vulnerable to eavesdropping. DAM applies controlled per-path symbol delays at the transmitter to coherently align the multipath components at the intended user, enhancing the received signal power, while simultaneously creating delay misalignment at the eavesdropper (Eve). To mitigate sensing degradation caused by multipath propagation, we propose a two-stage protocol that first estimates the angle and then the delay of the line-of-sight (LoS) path after suppressing multipath interference. We derive the secrecy spectral efficiency (SSE) and the Cramer-Rao (CRB) of the target delay. Finally, we develop a path-based zero-forcing (ZF) precoding framework and formulate a max-min SSE design under CRB and power constraints. Simulation results show DAM significantly outperforms the strongest-path (SP) benchmark in terms of SSE, while meeting sensing requirements, since intentional delay alignment at legitimate users degrades reception at Eve.

</details>


### [21] [TCDA: Robust 2D-DOA Estimation for Defective L-Shaped Arrays](https://arxiv.org/abs/2602.21146)
*Wenlong Wang,Tianyang Zhang,Tailun Dong,Lei Zhang*

Main category: cs.IT

TL;DR: 提出TCDA算法，通过张量补全解决故障阵列DOA估计问题，将物理缺陷转化为虚拟张量空间的数据恢复任务


<details>
  <summary>Details</summary>
Motivation: 传统基于张量的DOA估计算法在阵列存在故障或稀疏结构时性能严重下降，因为故障阵列破坏了所需的流形结构

Method: 通过子阵列划分、互相关和维度重塑构建不完整的三阶PARAFAC张量，利用张量的固有低秩结构，采用基于交替最小二乘的算法直接从观测数据中恢复包含DOA参数的因子矩阵

Result: 该方法提供了软件定义的"自愈"能力，对随机元素故障表现出卓越的鲁棒性，无需额外的DOA估计处理步骤

Conclusion: TCDA算法成功将物理阵列缺陷问题转化为张量补全问题，为故障阵列的DOA估计提供了有效的解决方案

Abstract: While tensor-based methods excel at Direction-of-Arrival (DOA) estimation, their performance degrades severely with faulty or sparse arrays that violate the required manifold structure. To address this challenge, we propose Tensor Completion for Defective Arrays (TCDA), a robust algorithm that reformulates the physical imperfection problem as a data recovery task within a virtual tensor space. We present a detailed derivation for constructing an incomplete third-order Parallel Factor Analysis (PARAFAC) tensor from the faulty array signals via subarray partitioning, cross-correlation, and dimensional reshaping. Leveraging the tensor's inherent low-rank structure, an Alternating Least Squares (ALS)-based algorithm directly recovers the factor matrices embedding the DOA parameters from the incomplete observations. This approach provides a software-defined 'self-healing' capability, demonstrating exceptional robustness against random element failures without requiring additional processing steps for DOA estimation.

</details>


### [22] [Phase-Aware Localization in Pinching Antenna Systems: CRLB Analysis and ML Estimation](https://arxiv.org/abs/2602.21162)
*Hao Feng,Ebrahim Bedeer,Ming Zeng,Xingwang Li,Shimin Gong,Quoc-Viet Pham*

Main category: cs.IT

TL;DR: 该论文研究了在夹持天线系统中利用接收信号幅度和相位信息进行用户定位，相比现有仅使用幅度信息的方法，显著提高了定位精度。


<details>
  <summary>Details</summary>
Motivation: 夹持天线系统是高频无线通信的有前景架构，现有定位方法仅利用幅度信息，忽略了相位信息，限制了定位精度。本文旨在通过联合利用幅度和相位信息来提高定位性能。

Method: 建立了包含自由空间路径损耗、波导衰减和距离相关相位旋转的复基带信号模型；推导了关于用户位置的Fisher信息矩阵和CRLB/PEB闭式表达式；开发了联合考虑幅度和相位的最大似然估计器；针对非凸优化问题，提出了粗网格搜索和Levenberg-Marquardt细化的两阶段解决方案。

Result: 数值结果表明，所提出的相位感知估计器在定位精度方面优于现有的仅幅度方法。

Conclusion: 通过联合利用接收信号的幅度和相位信息，可以显著提高夹持天线系统中的用户定位精度，相位信息对定位性能有重要贡献。

Abstract: Pinching antenna systems (PASS) have recently emerged as a promising architecture for high-frequency wireless communications. In this letter, we investigate localization in PASS by jointly exploiting the received signal amplitude and phase information, unlike recent works that consider only the amplitude information. A complex baseband signal model is formulated to capture free-space path loss, waveguide attenuation, and distance-dependent phase rotation between the user and each pinching antenna. Using this model, we derive the Fisher information matrix (FIM) with respect to the user location and obtain closed-form expressions for the Cramer-Rao lower bound (CRLB) and the position error bound (PEB). A maximum likelihood (ML) estimator that jointly considers the received signal amplitude and phase is developed to estimate the unknown user location. Given the non-convexity of the estimation problem, a two-stage solution combining coarse grid search and Levenberg-Marquardt refinement is proposed. Numerical results demonstrate that the proposed phase-aware estimator outperforms existing amplitude-only method in terms of positioning accuracy.

</details>


### [23] [Wireless-Fed Pinching-Antenna Systems with Horn Antennas](https://arxiv.org/abs/2602.21167)
*Hao Feng,Ming Zeng,Ebrahim Bedeer,Xingwang Li,Octavia A. Dobre,Zhiguo Ding*

Main category: cs.IT

TL;DR: 提出无线馈电夹持天线架构，使用高定向喇叭天线和全双工中继来扩展高频通信覆盖范围，通过联合优化天线位置、中继增益和基站功率来最小化总功耗。


<details>
  <summary>Details</summary>
Motivation: 夹持天线系统通过介质波导和可调天线增强高频无线通信覆盖，但受限于波导衰减和线路安装要求，覆盖范围有限。需要解决这些限制以实现更高效的覆盖扩展。

Method: 提出无线馈电夹持天线架构，在基站和波导输入之间引入配备喇叭天线的全双工放大转发中继，消除自干扰。建立总功率最小化问题，联合优化夹持天线位置、中继增益和基站发射功率，通过分析端到端信噪比结构获得闭式解。

Result: 推导出最优夹持天线位置的闭式解（平衡波导衰减和自由空间路径损耗），以及最优中继增益和发射功率的闭式表达式。数值结果表明，所提方案在总功耗方面显著优于无中继的传统系统和固定天线中继辅助传输。

Conclusion: 无线馈电夹持天线架构通过高定向喇叭天线和全双工中继有效扩展高频通信覆盖范围，联合优化设计显著降低系统总功耗，为高频无线通信提供实用解决方案。

Abstract: Pinching-antenna systems have recently emerged as a promising solution for enhancing coverage in high-frequency wireless communications by guiding signals through dielectric waveguides and radiating them via position-adjustable antennas. However, their practical deployment is fundamentally constrained by waveguide attenuation and line-installation requirements, which limit the achievable coverage range. To address this challenge, this paper investigates a wireless-fed pinching-antenna architecture that employs highly directional horn antennas to enable efficient coverage extension. Specifically, a full-duplex amplify-and-forward relay equipped with horn antennas is introduced between the base station and the waveguide input, which significantly improves the link budget in high-frequency bands while effectively eliminating self-interference. On this basis, we formulate a total power minimization problem subject to a quality-of-service constraint at the user equipment, involving the joint optimization of the pinching-antenna position, the relay amplification gain, and the base station transmit power. By exploiting the structure of the end-to-end signal-to-noise ratio, the optimal pinching-antenna position is first obtained in closed form by balancing waveguide attenuation and free-space path loss. Subsequently, closed-form expressions for the optimal relay gain and transmit power are derived. Numerical results demonstrate that the proposed scheme substantially outperforms conventional systems without relaying and relay-assisted transmission with fixed antennas in terms of total power consumption.

</details>
